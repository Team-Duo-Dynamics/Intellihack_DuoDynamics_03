{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "from pathlib import Path\n",
    "import markdown\n",
    "import pypdf\n",
    "from tqdm import tqdm\n",
    "from google import genai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "GOOGLE_API_KEY = \"AIzaSyB9gjlPn8XxGQ39uVPpDKLUbnt1NdbzyvE\"\n",
    "\n",
    "client = genai.Client(api_key=GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"Extract text from PDF files\"\"\"\n",
    "    text = \"\"\n",
    "    try:\n",
    "        with open(pdf_path, 'rb') as file:\n",
    "            reader = pypdf.PdfReader(file)\n",
    "            for page in reader.pages:\n",
    "                text += page.extract_text() + \"\\n\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting text from {pdf_path}: {e}\")\n",
    "    return text\n",
    "\n",
    "def extract_text_from_markdown(md_path):\n",
    "    \"\"\"Extract text from Markdown files\"\"\"\n",
    "    try:\n",
    "        with open(md_path, 'r', encoding='utf-8') as file:\n",
    "            md_content = file.read()\n",
    "            html = markdown.markdown(md_content)\n",
    "            text = re.sub(r'<[^>]+>', ' ', html)\n",
    "            return text\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting text from {md_path}: {e}\")\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_chunks(text, chunk_size=1000, overlap=200):\n",
    "    \"\"\"Split text into overlapping chunks\"\"\"\n",
    "    chunks = []\n",
    "    for i in range(0, len(text), chunk_size - overlap):\n",
    "        chunk = text[i:i + chunk_size]\n",
    "        if len(chunk) > 200:  # Only keep chunks with meaningful content\n",
    "            chunks.append(chunk)\n",
    "    return chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_qa_pairs_with_gemini(chunk, num_pairs=3):\n",
    "    \"\"\"Generate QA pairs using Gemini API\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    Based on the following text, generate {num_pairs} relevant question-answer pairs.\n",
    "    For each pair, the question should be answerable from the text, and the answer should be comprehensive.\n",
    "    Return the result in the following JSON format:\n",
    "    [\n",
    "      {{\n",
    "        \"question\": \"Question 1\",\n",
    "        \"answer\": \"Answer 1\"\n",
    "      }},\n",
    "      ...\n",
    "    ]\n",
    "    \n",
    "    Text:\n",
    "    {chunk}\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    try:\n",
    "        response = client.models.generate_content(\n",
    "            model=\"gemini-2.0-flash\",\n",
    "            contents=[prompt]\n",
    "        )\n",
    "        # Extract JSON from response\n",
    "        response_text = response.text\n",
    "        # Find JSON content (between first [ and last ])\n",
    "        json_match = re.search(r'\\[\\s*{.*}\\s*\\]', response_text, re.DOTALL)\n",
    "        if json_match:\n",
    "            json_str = json_match.group(0)\n",
    "            qa_pairs = json.loads(json_str)\n",
    "            # Add context to each QA pair\n",
    "            for pair in qa_pairs:\n",
    "                pair[\"context\"] = chunk\n",
    "            return qa_pairs\n",
    "        else:\n",
    "            print(f\"Failed to parse JSON from response: {response_text}\")\n",
    "            return []\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating QA pairs with Gemini: {e}\")\n",
    "        return []\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_files(dataset_dir):\n",
    "    \"\"\"Process all PDF and Markdown files in the given directory\"\"\"\n",
    "    all_qa_pairs = []\n",
    "    \n",
    "    # Process PDF files\n",
    "    pdf_dir = dataset_dir\n",
    "    if os.path.exists(pdf_dir):\n",
    "        pdf_files = [\"q3_dataset/2501.12948v1.pdf\"]\n",
    "        print(\"pdf\", pdf_files)\n",
    "        for pdf_file in tqdm(pdf_files, desc=\"Processing PDFs\"):\n",
    "            text = extract_text_from_pdf(pdf_file)\n",
    "            \n",
    "            chunks = split_into_chunks(text)\n",
    "            for chunk in tqdm(chunks, desc=f\"Generating QA pairs for {pdf_file}\", leave=False):\n",
    "                qa_pairs = generate_qa_pairs_with_gemini(chunk)\n",
    "                all_qa_pairs.extend(qa_pairs)\n",
    "                break\n",
    "    \n",
    "    # Process Markdown files\n",
    "    md_dir = dataset_dir\n",
    "    if os.path.exists(md_dir):\n",
    "        md_files = [\"q3_dataset/dataset.md\", \"q3_dataset/deepseekv3-cost-explained.md\", \"q3_dataset/design-notes-3fs.md\", \"q3_dataset/open-source-week.md\"]\n",
    "        for md_file in tqdm(md_files, desc=\"Processing Markdown\"):\n",
    "            text = extract_text_from_markdown(md_file)\n",
    "            chunks = split_into_chunks(text)\n",
    "            for chunk in tqdm(chunks, desc=f\"Generating QA pairs for {md_file}\", leave=False):\n",
    "                qa_pairs = generate_qa_pairs_with_gemini(chunk)\n",
    "                all_qa_pairs.extend(qa_pairs)\n",
    "                \n",
    "            \n",
    "    \n",
    "    return all_qa_pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pdf ['q3_dataset/2501.12948v1.pdf']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PDFs: 100%|██████████| 1/1 [00:03<00:00,  3.94s/it]\n",
      "Processing Markdown:  25%|██▌       | 1/4 [00:25<01:15, 25.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generating QA pairs with Gemini: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'Resource has been exhausted (e.g. check quota).', 'status': 'RESOURCE_EXHAUSTED'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generating QA pairs with Gemini: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'Resource has been exhausted (e.g. check quota).', 'status': 'RESOURCE_EXHAUSTED'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generating QA pairs with Gemini: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'Resource has been exhausted (e.g. check quota).', 'status': 'RESOURCE_EXHAUSTED'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generating QA pairs with Gemini: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'Resource has been exhausted (e.g. check quota).', 'status': 'RESOURCE_EXHAUSTED'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Markdown:  50%|█████     | 2/4 [00:40<00:39, 19.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generating QA pairs with Gemini: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'Resource has been exhausted (e.g. check quota).', 'status': 'RESOURCE_EXHAUSTED'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generating QA pairs with Gemini: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'Resource has been exhausted (e.g. check quota).', 'status': 'RESOURCE_EXHAUSTED'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generating QA pairs with Gemini: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'Resource has been exhausted (e.g. check quota).', 'status': 'RESOURCE_EXHAUSTED'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generating QA pairs with Gemini: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'Resource has been exhausted (e.g. check quota).', 'status': 'RESOURCE_EXHAUSTED'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generating QA pairs with Gemini: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'Resource has been exhausted (e.g. check quota).', 'status': 'RESOURCE_EXHAUSTED'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generating QA pairs with Gemini: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'Resource has been exhausted (e.g. check quota).', 'status': 'RESOURCE_EXHAUSTED'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generating QA pairs with Gemini: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'Resource has been exhausted (e.g. check quota).', 'status': 'RESOURCE_EXHAUSTED'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generating QA pairs with Gemini: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'Resource has been exhausted (e.g. check quota).', 'status': 'RESOURCE_EXHAUSTED'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generating QA pairs with Gemini: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'Resource has been exhausted (e.g. check quota).', 'status': 'RESOURCE_EXHAUSTED'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generating QA pairs with Gemini: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'Resource has been exhausted (e.g. check quota).', 'status': 'RESOURCE_EXHAUSTED'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generating QA pairs with Gemini: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'Resource has been exhausted (e.g. check quota).', 'status': 'RESOURCE_EXHAUSTED'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generating QA pairs with Gemini: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'Resource has been exhausted (e.g. check quota).', 'status': 'RESOURCE_EXHAUSTED'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generating QA pairs with Gemini: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'Resource has been exhausted (e.g. check quota).', 'status': 'RESOURCE_EXHAUSTED'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generating QA pairs with Gemini: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'Resource has been exhausted (e.g. check quota).', 'status': 'RESOURCE_EXHAUSTED'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generating QA pairs with Gemini: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'Resource has been exhausted (e.g. check quota).', 'status': 'RESOURCE_EXHAUSTED'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generating QA pairs with Gemini: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'Resource has been exhausted (e.g. check quota).', 'status': 'RESOURCE_EXHAUSTED'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generating QA pairs with Gemini: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'Resource has been exhausted (e.g. check quota).', 'status': 'RESOURCE_EXHAUSTED'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generating QA pairs with Gemini: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'Resource has been exhausted (e.g. check quota).', 'status': 'RESOURCE_EXHAUSTED'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generating QA pairs with Gemini: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'Resource has been exhausted (e.g. check quota).', 'status': 'RESOURCE_EXHAUSTED'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generating QA pairs with Gemini: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'Resource has been exhausted (e.g. check quota).', 'status': 'RESOURCE_EXHAUSTED'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generating QA pairs with Gemini: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'Resource has been exhausted (e.g. check quota).', 'status': 'RESOURCE_EXHAUSTED'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generating QA pairs with Gemini: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'Resource has been exhausted (e.g. check quota).', 'status': 'RESOURCE_EXHAUSTED'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generating QA pairs with Gemini: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'Resource has been exhausted (e.g. check quota).', 'status': 'RESOURCE_EXHAUSTED'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generating QA pairs with Gemini: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'Resource has been exhausted (e.g. check quota).', 'status': 'RESOURCE_EXHAUSTED'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Markdown:  75%|███████▌  | 3/4 [01:38<00:37, 37.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generating QA pairs with Gemini: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'Resource has been exhausted (e.g. check quota).', 'status': 'RESOURCE_EXHAUSTED'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generating QA pairs with Gemini: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'Resource has been exhausted (e.g. check quota).', 'status': 'RESOURCE_EXHAUSTED'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generating QA pairs with Gemini: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'Resource has been exhausted (e.g. check quota).', 'status': 'RESOURCE_EXHAUSTED'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generating QA pairs with Gemini: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'Resource has been exhausted (e.g. check quota).', 'status': 'RESOURCE_EXHAUSTED'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Markdown: 100%|██████████| 4/4 [01:43<00:00, 25.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generating QA pairs with Gemini: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'Resource has been exhausted (e.g. check quota).', 'status': 'RESOURCE_EXHAUSTED'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "qs = process_files(\"qa_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What are some of the benefits and drawbacks of using reinforcement learning (RL) to train DeepSeek-R1-Zero?',\n",
       " 'answer': 'DeepSeek-R1-Zero, trained via RL, naturally demonstrates remarkable reasoning capabilities and emerges with numerous powerful and intriguing reasoning behaviors. However, it also encounters challenges such as poor readability and language mixing.',\n",
       " 'context': 'DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via\\nReinforcement Learning\\nDeepSeek-AI\\nresearch@deepseek.com\\nAbstract\\nWe introduce our first-generation reasoning models, DeepSeek-R1-Zero and DeepSeek-R1.\\nDeepSeek-R1-Zero, a model trained via large-scale reinforcement learning (RL) without super-\\nvised fine-tuning (SFT) as a preliminary step, demonstrates remarkable reasoning capabilities.\\nThrough RL, DeepSeek-R1-Zero naturally emerges with numerous powerful and intriguing\\nreasoning behaviors. However, it encounters challenges such as poor readability, and language\\nmixing. To address these issues and further enhance reasoning performance, we introduce\\nDeepSeek-R1, which incorporates multi-stage training and cold-start data before RL. DeepSeek-\\nR1 achieves performance comparable to OpenAI-o1-1217 on reasoning tasks. To support the\\nresearch community, we open-source DeepSeek-R1-Zero, DeepSeek-R1, and six dense models\\n(1.5B, 7B, 8B, 14B, 32B, 70B) distilled from DeepSeek-R1 based o'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file created at qa_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Define the CSV file path\n",
    "csv_file_path = \"qa_dataset.csv\"\n",
    "\n",
    "# Define the field names\n",
    "fieldnames = ['question', 'answer', 'context']\n",
    "\n",
    "# Write the data to the CSV file\n",
    "with open(csv_file_path, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for qa_pair in qs:\n",
    "        writer.writerow(qa_pair)\n",
    "\n",
    "print(f\"CSV file created at {csv_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(qa_pairs, output_path):\n",
    "    \"\"\"Create and save the dataset in a format suitable for fine-tuning\"\"\"\n",
    "    # Split into train and validation sets\n",
    "    import random\n",
    "    random.shuffle(qa_pairs)\n",
    "    split_idx = int(0.9 * len(qa_pairs))\n",
    "    train_data = qa_pairs[:split_idx]\n",
    "    val_data = qa_pairs[split_idx:]\n",
    "    \n",
    "    # Format data for Llama fine-tuning\n",
    "    formatted_train = format_for_llama(train_data)\n",
    "    formatted_val = format_for_llama(val_data)\n",
    "    \n",
    "    # Save datasets\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    with open(os.path.join(output_path, \"train.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(formatted_train, f, indent=2)\n",
    "    \n",
    "    with open(os.path.join(output_path, \"val.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(formatted_val, f, indent=2)\n",
    "        \n",
    "    print(f\"Created dataset with {len(formatted_train)} training samples and {len(formatted_val)} validation samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(qa_pairs, output_path):\n",
    "    \"\"\"Create and save the dataset in a format suitable for fine-tuning\"\"\"\n",
    "    # Split into train and validation sets\n",
    "    import random\n",
    "    random.shuffle(qa_pairs)\n",
    "    split_idx = int(0.9 * len(qa_pairs))\n",
    "    train_data = qa_pairs[:split_idx]\n",
    "    val_data = qa_pairs[split_idx:]\n",
    "    \n",
    "    # Format data for Llama fine-tuning\n",
    "    formatted_train = format_for_llama(train_data)\n",
    "    formatted_val = format_for_llama(val_data)\n",
    "    \n",
    "    # Save datasets\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    with open(os.path.join(output_path, \"train.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(formatted_train, f, indent=2)\n",
    "    \n",
    "    with open(os.path.join(output_path, \"val.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(formatted_val, f, indent=2)\n",
    "        \n",
    "    print(f\"Created dataset with {len(formatted_train)} training samples and {len(formatted_val)} validation samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_for_llama(qa_pairs):\n",
    "    \"\"\"Format QA pairs for Llama fine-tuning\"\"\"\n",
    "    formatted_data = []\n",
    "    \n",
    "    for pair in qa_pairs:\n",
    "        formatted_data.append({\n",
    "            \"text\": f\"### Question: {pair['question']}\\n\\n### Context: {pair['context']}\\n\\n### Answer: {pair['answer']}\"\n",
    "        })\n",
    "    \n",
    "    return formatted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dataset with 2 training samples and 1 validation samples\n"
     ]
    }
   ],
   "source": [
    "create_dataset(qs, \"qa_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mqa_dataset.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"qa_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
